{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1zJVYReKdP3H7TIC2P3WxNL871QoZiBA5",
      "authorship_tag": "ABX9TyMtRf9zm7/2JImFCfQDGlhE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KodumuruRaja/Gen_AI/blob/main/MISTRAL_7B_Q%26A_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtWBEeEo3ZJk",
        "outputId": "723a85c7-e00e-4940-e2df-e27f88806740"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fastapi\n",
            "  Downloading fastapi-0.104.1-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi) (3.7.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (1.10.13)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions>=4.8.0 (from fastapi)\n",
            "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi) (3.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi) (1.2.0)\n",
            "Installing collected packages: typing-extensions, starlette, fastapi\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fastapi-0.104.1 starlette-0.27.0 typing-extensions-4.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySIfB-GX3lxB",
        "outputId": "fe03e389-8979-4df8-d614-33f5ec884ab7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.0.348-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-core<0.1,>=0.0.12 (from langchain)\n",
            "  Downloading langchain_core-0.0.12-py3-none-any.whl (181 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.5/181.5 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1.0,>=0.0.63 (from langchain)\n",
            "  Downloading langsmith-0.0.69-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.1,>=0.0.12->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.1,>=0.0.12->langchain) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.1,>=0.0.12->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.1,>=0.0.12->langchain) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, langsmith, jsonpatch, langchain-core, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.6.3 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.348 langchain-core-0.0.12 langsmith-0.0.69 marshmallow-3.20.1 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install uvicorn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdvEmh8O3sQq",
        "outputId": "fe5afe96-c0cf-4247-bef6-702fc489fb31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.24.0.post1-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m880.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n",
            "Collecting h11>=0.8 (from uvicorn)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (4.8.0)\n",
            "Installing collected packages: h11, uvicorn\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 uvicorn-0.24.0.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install aiofiles"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g67pQDW33wT9",
        "outputId": "d6413b97-b9a9-407a-a609-862e027dd37c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting aiofiles\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: aiofiles\n",
            "Successfully installed aiofiles-23.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lF6OwITv32UO",
        "outputId": "99f26ad0-bf67-4716-8758-82cbbacb1496"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf2\n",
            "Successfully installed pypdf2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-multipart"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMpWN7Mv4JGq",
        "outputId": "ddc47a64-024e-483f-8553-8d82bc034d7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-multipart\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m653.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-multipart\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed python-multipart-0.0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPvBO0kRL5s6",
        "outputId": "605f3cfe-ead3-4f2b-b914-94d871d62502"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-3.17.1-py3-none-any.whl (277 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m277.6/277.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-3.17.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ctransformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjR3xSibMWJb",
        "outputId": "f2f7a001-c6f3-40d4-a7c5-09d151822f56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ctransformers\n",
            "  Downloading ctransformers-0.2.27-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from ctransformers) (0.19.4)\n",
            "Requirement already satisfied: py-cpuinfo<10.0.0,>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from ctransformers) (9.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (4.8.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->ctransformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->ctransformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->ctransformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->ctransformers) (2023.11.17)\n",
            "Installing collected packages: ctransformers\n",
            "Successfully installed ctransformers-0.2.27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_Q8stlXQAYM",
        "outputId": "d3f86b62-a470-444b-986c-6798afb6ebc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence_transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.35.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.16.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (3.8.1)\n",
            "Collecting sentencepiece (from sentence_transformers)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.8.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n",
            "Building wheels for collected packages: sentence_transformers\n",
            "  Building wheel for sentence_transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=599c885618b161d21f69f848ef290a6dfc20007727bbcdc8010a3d27f5eb5bd4\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built sentence_transformers\n",
            "Installing collected packages: sentencepiece, sentence_transformers\n",
            "Successfully installed sentence_transformers-2.2.2 sentencepiece-0.1.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEponW7hUpSI",
        "outputId": "742835f5-8100-4b46-a8c6-56c80ba453fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.7.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI, Form, Request, Response, File, Depends, HTTPException, status\n",
        "from fastapi.responses import RedirectResponse\n",
        "from fastapi.staticfiles import StaticFiles\n",
        "from fastapi.templating import Jinja2Templates\n",
        "from fastapi.encoders import jsonable_encoder\n",
        "from langchain.llms import CTransformers\n",
        "from langchain.chains import QAGenerationChain\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.chains import RetrievalQA\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import uvicorn\n",
        "import aiofiles\n",
        "from PyPDF2 import PdfReader\n",
        "import csv\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "app.mount(\"/content/sample_data\", StaticFiles(directory=\"sample_data\"), name=\"sample_data\")\n",
        "\n",
        "#templates = Jinja2Templates(directory=\"templates\")\n",
        "\n",
        "def load_llm():\n",
        "    # Load the locally downloaded model here\n",
        "    llm = CTransformers(\n",
        "        model = \"/content/drive/MyDrive/mistral-7b-instruct-v0.1.Q4_K_S.gguf\",\n",
        "        model_type=\"mistral\",\n",
        "        max_new_tokens = 1048,\n",
        "        temperature = 0.3\n",
        "    )\n",
        "    return llm\n",
        "\n",
        "def file_processing(file_path):\n",
        "\n",
        "    # Load data from PDF\n",
        "    loader = PyPDFLoader(file_path)\n",
        "    data = loader.load()\n",
        "\n",
        "    question_gen = ''\n",
        "\n",
        "    for page in data:\n",
        "        question_gen += page.page_content\n",
        "\n",
        "    splitter_ques_gen = RecursiveCharacterTextSplitter(\n",
        "        chunk_size = 1000,\n",
        "        chunk_overlap = 100\n",
        "    )\n",
        "\n",
        "    chunks_ques_gen = splitter_ques_gen.split_text(question_gen)\n",
        "\n",
        "    document_ques_gen = [Document(page_content=t) for t in chunks_ques_gen]\n",
        "\n",
        "    splitter_ans_gen = RecursiveCharacterTextSplitter(\n",
        "        chunk_size = 300,\n",
        "        chunk_overlap = 30\n",
        "    )\n",
        "\n",
        "\n",
        "    document_answer_gen = splitter_ans_gen.split_documents(\n",
        "        document_ques_gen\n",
        "    )\n",
        "\n",
        "    return document_ques_gen, document_answer_gen\n",
        "\n",
        "def llm_pipeline(file_path):\n",
        "\n",
        "    document_ques_gen, document_answer_gen = file_processing(file_path)\n",
        "\n",
        "\n",
        "\n",
        "    llm_ques_gen_pipeline = load_llm()\n",
        "\n",
        "    prompt_template = \"\"\"\n",
        "    You are an expert at creating questions based on coding materials and documentation.\n",
        "    Your goal is to prepare a coder or programmer for their exam and coding tests.\n",
        "    You do this by asking questions about the text below:\n",
        "\n",
        "    ------------\n",
        "    {text}\n",
        "    ------------\n",
        "\n",
        "    Create questions that will prepare the coders or programmers for their tests.\n",
        "    Make sure not to lose any important information.\n",
        "\n",
        "    QUESTIONS:\n",
        "    \"\"\"\n",
        "\n",
        "    PROMPT_QUESTIONS = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
        "\n",
        "    refine_template = (\"\"\"\n",
        "    You are an expert at creating practice questions based on coding material and documentation.\n",
        "    Your goal is to help a coder or programmer prepare for a coding test.\n",
        "    We have received some practice questions to a certain extent: {existing_answer}.\n",
        "    We have the option to refine the existing questions or add new ones.\n",
        "    (only if necessary) with some more context below.\n",
        "    ------------\n",
        "    {text}\n",
        "    ------------\n",
        "\n",
        "    Given the new context, refine the original questions in English.\n",
        "    If the context is not helpful, please provide the original questions.\n",
        "    QUESTIONS:\n",
        "    \"\"\"\n",
        "    )\n",
        "\n",
        "    REFINE_PROMPT_QUESTIONS = PromptTemplate(\n",
        "        input_variables=[\"existing_answer\", \"text\"],\n",
        "        template=refine_template,\n",
        "    )\n",
        "\n",
        "    ques_gen_chain = load_summarize_chain(llm = llm_ques_gen_pipeline,\n",
        "                                            chain_type = \"refine\",\n",
        "                                            verbose = True,\n",
        "                                            question_prompt=PROMPT_QUESTIONS,\n",
        "                                            refine_prompt=REFINE_PROMPT_QUESTIONS)\n",
        "\n",
        "    ques = ques_gen_chain.run(document_ques_gen)\n",
        "\n",
        "    embeddings = HuggingFaceBgeEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
        "\n",
        "    vector_store = FAISS.from_documents(document_answer_gen, embeddings)\n",
        "\n",
        "    llm_answer_gen = load_llm()\n",
        "\n",
        "    ques_list = ques.split(\"\\n\")\n",
        "    filtered_ques_list = [element for element in ques_list if element.endswith('?') or element.endswith('.')]\n",
        "\n",
        "    answer_generation_chain = RetrievalQA.from_chain_type(llm=llm_answer_gen,\n",
        "                                                chain_type=\"stuff\",\n",
        "                                                retriever=vector_store.as_retriever())\n",
        "\n",
        "    return answer_generation_chain, filtered_ques_list\n",
        "\n",
        "\n",
        "def get_csv (file_path):\n",
        "    answer_generation_chain, ques_list = llm_pipeline(file_path)\n",
        "    for question in ques_list:\n",
        "        print(\"Question: \", question)\n",
        "        answer = answer_generation_chain.run(question)\n",
        "        print(\"Answer: \", answer)\n",
        "        print(\"--------------------------------------------------\\n\\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "GwzoFasmwiSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_csv(\"/content/sdgp.pdf\")"
      ],
      "metadata": {
        "id": "T_va-h6-3XmL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e1fdbfa-051b-456a-a7a7-056efa694004"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RefineDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "    You are an expert at creating questions based on coding materials and documentation.\n",
            "    Your goal is to prepare a coder or programmer for their exam and coding tests.\n",
            "    You do this by asking questions about the text below:\n",
            "\n",
            "    ------------\n",
            "    IN THE YEAR 2015, LEADERS FROM 193 COUNTRIES OF THE WORLD \n",
            "CAME TOGETHER TO FACE THE FUTURE.\n",
            "And what they saw was daunting. Famines. Drought. Wars. Plagues. Poverty. \n",
            "Not just in some faraway place, but in their own cities and towns and villages.\n",
            "They knew things didn’t have to be this way. They knew we had enough  \n",
            "food to feed the world, but that it wasn’t getting shared. They knew there \n",
            "were medicines for HIV and other diseases, but they cost a lot. They knew  \n",
            "that earthquakes and floods were inevitable, but that the high death  \n",
            "tolls were not. \n",
            "They also knew that billions of people worldwide shared their hope for a \n",
            "better future.\n",
            "So leaders from these countries created a plan called the Sustainable \n",
            "Development Goals (SDGs). This set of 17 goals imagines a future just 15 years \n",
            "off that would be rid of poverty and hunger, and safe from the worst effects of \n",
            "climate change. It’s an ambitious plan. \n",
            "But there’s ample evidence that we can succeed. In the past 15 years, the\n",
            "    ------------\n",
            "\n",
            "    Create questions that will prepare the coders or programmers for their tests.\n",
            "    Make sure not to lose any important information.\n",
            "\n",
            "    QUESTIONS:\n",
            "    \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (513) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (514) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (515) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (516) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (517) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (518) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (519) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (520) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (521) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (522) exceeded maximum context length (512).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "    You are an expert at creating practice questions based on coding material and documentation.\n",
            "    Your goal is to help a coder or programmer prepare for a coding test.\n",
            "    We have received some practice questions to a certain extent: \n",
            "    Q1: What year did leaders from 193 countries come together to create the Sustainable Development Goals (SDGs)?\n",
            "    Q2: What were some of the daunting challenges that world leaders saw in 2015?\n",
            "    Q3: What were some of the solutions that world leaders aimed to achieve with the SDGs?\n",
            "    Q4: How many goals did the SDGs consist of, and what were they?\n",
            "    Q5: What evidence is there that we can succeed in achieving the SDGs?\n",
            "    Q6: Were the SDGiven -15 the SDG.\n",
            "    We have the option to refine the existing questions or add new ones.\n",
            "    (only if necessary) with some more context below.\n",
            "    ------------\n",
            "    But there’s ample evidence that we can succeed. In the past 15 years, the \n",
            "international community cut extreme poverty in half. \n",
            "Now we can finish the job.\n",
            "The United Nations Development Programme (UNDP) is one of the leading \n",
            "organizations working to fulfil the SDGs by the year 2030. Present in nearly \n",
            "170 countries and territories, we help nations make the Goals a reality.  \n",
            "We also champion the Goals so that people everywhere know how to  \n",
            "do their part. \n",
            "UNDP is proud to continue as a leader in this global movement.\n",
            "Learn about the Sustainable Development Goals.  What’s your Goal?\n",
            "    ------------\n",
            "\n",
            "    Given the new context, refine the original questions in English.\n",
            "    If the context is not helpful, please provide the original questions.\n",
            "    QUESTIONS:\n",
            "    \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (513) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (514) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (515) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (516) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (517) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (518) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (519) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (520) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (521) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (522) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (523) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (524) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (525) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (526) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (527) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (528) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (529) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (530) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (531) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (532) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (533) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (534) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (535) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (536) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (537) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (538) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (539) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (540) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (541) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (542) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (543) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (544) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (545) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (546) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (547) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (548) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (549) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (550) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (551) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (552) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (553) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (554) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (555) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (556) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (557) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (558) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (559) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (560) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (561) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (562) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (563) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (564) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (565) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (566) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (567) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (568) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (569) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (570) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (571) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (572) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (573) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (574) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (575) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (576) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (577) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (578) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (579) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (580) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (581) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (582) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (583) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (584) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (585) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (586) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (587) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (588) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (589) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (590) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (591) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (592) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (593) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (594) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (595) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (596) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (597) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (598) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (599) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (600) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (601) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (602) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (603) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (604) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (605) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (606) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (607) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (608) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (609) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (610) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (611) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (612) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (613) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (614) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (615) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (616) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (617) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (618) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (619) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (620) exceeded maximum context length (512).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Question:  1. In what year did leaders from 193 countries come together to create the Sustainable Development Goals (SDGs)?\n",
            "Answer:   The leaders came together in the year 2015.\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "Question:      2. What were some of the daunting challenges that world leaders saw in 2015?\n",
            "Answer:   Famines, drought, wars, plagues and poverty, not just in some faraway place but in their own cities and towns and villages.\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "Question:      3. What were some of the solutions that world leaders aimed to achieve with the SDGs?\n",
            "Answer:   Some of the solutions that world leaders aimed to achieve with the SDGs include eradicating poverty, reducing inequality, improving access to clean energy, protecting the planet and its resources, and promoting peace and prosperity for all people.\n",
            "--------------------------------------------------\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y8yorzCdLpYu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}