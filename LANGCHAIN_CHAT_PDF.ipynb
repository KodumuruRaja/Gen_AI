{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c44f2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "import fitz\n",
    "import PIL.Image as Image\n",
    "import io\n",
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = \"[YOUR-API-KEY]\"\n",
    "\n",
    "def save_image(block, page_num, base_path):\n",
    "    \"\"\"Saves the image from the block and returns the file path.\"\"\"\n",
    "    try:\n",
    "        image_filename = f\"image_page{page_num+1}_{block['number']}.{block['ext']}\"\n",
    "        image_folder = os.path.join(base_path, image_filename)\n",
    "        image = Image.open(io.BytesIO(block[\"image\"]))\n",
    "        image.save(image_folder)\n",
    "        print(\"Extracted images from pdf\")\n",
    "        return image_folder\n",
    "    except Exception as exe:\n",
    "        print(\"Error extracting images: \"+ str(exe))\n",
    "\n",
    "\n",
    "def process_text_block(block, page_num, line_number):\n",
    "    \"\"\"Processes a text block and returns formatted text.\"\"\"\n",
    "    text_content = []\n",
    "    for line in block[\"lines\"]:\n",
    "        line_text = \" \".join([span[\"text\"] for span in line[\"spans\"]])\n",
    "        if line_text.strip():\n",
    "            text_content.append((line_text.strip(), line_number, page_num + 1, block[\"bbox\"]))\n",
    "            line_number += 1\n",
    "    return text_content, line_number\n",
    "\n",
    "\n",
    "def extract_data_from_pdf(pdf_path, path):\n",
    "    \"\"\"Extracts text and images from a PDF, returning structured data.\"\"\"\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        extracted_data = []\n",
    "\n",
    "        for page_num in range(len(doc)):\n",
    "            page = doc.load_page(page_num)\n",
    "            blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "            line_number = 1\n",
    "            for block in blocks:\n",
    "                if block[\"type\"] == 0:  # Text block\n",
    "                    text_content, line_number = process_text_block(block, page_num, line_number)\n",
    "                    extracted_data.extend(text_content)\n",
    "\n",
    "                elif block[\"type\"] == 1:  # Image block\n",
    "                    image_path = save_image(block, page_num, image_save_path)\n",
    "                    extracted_data.append((\"<img>\" + image_path + \"</img>\", None, page_num + 1, block[\"bbox\"]))\n",
    "\n",
    "        doc.close()\n",
    "        print(\"Extracted data from pdf\")\n",
    "        return extracted_data\n",
    "\n",
    "    except Exception as exe:\n",
    "        print(\"Error extracting data from pdf: \"+ str(exe))\n",
    "\n",
    "def process_extracted_data(data):\n",
    "    \"\"\"Processes extracted data for final output.\"\"\"\n",
    "    # Sort by page number and bbox upper left corner\n",
    "    data.sort(key=lambda x: (x[2], x[3][1], x[3][0]))\n",
    "    return [item[0] for item in data ], [{ \"page\": item[2], \"line_number\": item[1]} for item in data]\n",
    "\n",
    "\n",
    "def pdf_2_txt(document, metadata):\n",
    "    try:\n",
    "        new_metadata = []\n",
    "        text = \"\"\n",
    "        current_line = \"1\"\n",
    "        tmp = \"\"\n",
    "        for i in range(len(document)-1):\n",
    "            if document[i+1].startswith(\"<img>\"):\n",
    "                text = text + document[i].strip(\".\") + \" \"\n",
    "\n",
    "            elif document[i].startswith(\"<img>\"):\n",
    "                text = text + document[i] + \"\\n\"\n",
    "\n",
    "            else:\n",
    "                text = text + document[i] + \" \"\n",
    "                if metadata[i]['line_number'] == 1:\n",
    "                    new_metadata.append({'line_number': tmp, 'page': metadata[i]['page']})\n",
    "                else:\n",
    "                    current_line = current_line + \"_\" + str(metadata[i]['line_number'])\n",
    "                    new_metadata.append({'line_number': tmp, 'page': metadata[i]['page']})\n",
    "\n",
    "            tmp = tmp + str(metadata[i]['line_number']) + \"_\"\n",
    "\n",
    "        #text_file_name = os.path.splitext(pdf_path)[0] + \".txt\"\n",
    "        with open(\"1.txt\", 'w', encoding=\"utf-8\") as text_file:\n",
    "            text_file.write(text)\n",
    "        print(\"Converted pdf to text\")\n",
    "        return metadata\n",
    "\n",
    "    except Exception as exe:\n",
    "        print(\"Error converting pdf to text: \"+ str(exe))\n",
    "\n",
    "\n",
    "\n",
    "def process_text_file(text_file_name=\"1.txt\"):\n",
    "    # using text loader to load text file\n",
    "    try:\n",
    "        loader = TextLoader(text_file_name, encoding='utf8')\n",
    "        documents = loader.load()\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "        texts = text_splitter.split_documents(documents)\n",
    "        return texts\n",
    "    \n",
    "def final(user_input):\n",
    "    # OpenAI Embeddings\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    #Chroma Vector DB\n",
    "    vectordb = Chroma.from_documents(documents=process_text_file(), \n",
    "                                     embedding=embeddings,\n",
    "                                     persist_directory=persist_directory)\n",
    "    vectordb.persist()\n",
    "\n",
    "    retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})\n",
    "    \n",
    "    # Chat Model\n",
    "    llm = ChatOpenAI(model_name='gpt-3.5-turbo-1106')\n",
    "\n",
    "    qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)\n",
    "\n",
    "    query = f\"###Prompt {user_input}\"\n",
    "    try:\n",
    "        llm_response = qa(query)\n",
    "        #print(llm_response[\"result\"])\n",
    "        return llm_response[\"result\"]\n",
    "    except Exception as err:\n",
    "        #print('Exception occurred. Please try again', str(err))\n",
    "        return str(e)\n",
    "\n",
    "\n",
    "\n",
    "def main(pdf_path, ID):\n",
    "    extracted_data = extract_data_from_pdf(pdf_path, path)\n",
    "    document, metadata = process_extracted_data(extracted_data)\n",
    "    pdf_2_txt(document, metadata)\n",
    "    final(input(\"Enter your query\"))\n",
    "    os.remove(\"1.txt\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_path = \"C:/Users/Raja/Downloads/sdgp.pdf\"\n",
    "    ID = \"999-999-999\"\n",
    "    main(pdf_path, ID)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
